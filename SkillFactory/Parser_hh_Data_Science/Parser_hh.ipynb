{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Var. 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xlsxwriter # pip install XlsxWriter\n",
    "import requests # pip install requests\n",
    "from bs4 import BeautifulSoup as bs # pip install beautifulsoup4\n",
    "\n",
    "headers = {\n",
    "            'accept': '*/*', \n",
    "            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'\n",
    "            }\n",
    "vacancy = input('Укажите название вакансии: ')\n",
    "base_url = f'https://hh.ru/search/vacancy?area=1&search_period=30&text={vacancy}&page=' \n",
    "                                # area=1 - Москва, search_period=30 - За 30 последних дней, Data science\n",
    "pages = int(input('Укажите кол-во страниц для парсинга: '))\n",
    "jobs =[]\n",
    "\n",
    "def hh_parse(base_url, headers):\n",
    "        zero = 0\n",
    "        while pages > zero:\n",
    "                zero = str(zero)\n",
    "                session = requests.Session()\n",
    "                request = session.get(base_url + zero, headers = headers)\n",
    "                if request.status_code == 200:\n",
    "                        soup = bs(request.content, 'html.parser')\n",
    "                        divs = soup.find_all('div', attrs = {'data-qa': 'vacancy-serp__vacancy'})\n",
    "                        for div in divs:\n",
    "                                title = div.find('a', attrs = {'data-qa': 'vacancy-serp__vacancy-title'}).text\n",
    "                                compensation = div.find('div', attrs={'data-qa': 'vacancy-serp__vacancy-compensation'})\n",
    "                                if compensation == None: # Если зарплата не указана\n",
    "                                        compensation = 'None'\n",
    "                                else:\n",
    "                                        compensation = div.find('div', attrs={'data-qa': 'vacancy-serp__vacancy-compensation'}).text\n",
    "                                href = div.find('a', attrs = {'data-qa': 'vacancy-serp__vacancy-title'})['href']\n",
    "                                try:\n",
    "                                        company = div.find('a', attrs = {'data-qa': 'vacancy-serp__vacancy-employer'}).text\n",
    "                                except:\n",
    "                                        company = 'None'\n",
    "                                text1 = div.find('div', attrs = {'data-qa': 'vacancy-serp__vacancy_snippet_responsibility'}).text\n",
    "                                text2 = div.find('div', attrs = {'data-qa': 'vacancy-serp__vacancy_snippet_requirement'}).text\n",
    "                                content = text1 + '  ' + text2\n",
    "                                all_txt = [title, compensation, company, content, href]\n",
    "                                jobs.append(all_txt)\n",
    "                        zero = int(zero)\n",
    "                        zero += 1\n",
    "\n",
    "                else:\n",
    "                        print('error')\n",
    "\n",
    "                # Запись в Excel файл\n",
    "                workbook = xlsxwriter.Workbook('Vacancy.xlsx')\n",
    "                worksheet = workbook.add_worksheet()\n",
    "                # Добавим стили форматирования\n",
    "                bold = workbook.add_format({'bold': 1})\n",
    "                bold.set_align('center')\n",
    "                center_H_V = workbook.add_format()\n",
    "                center_H_V.set_align('center')\n",
    "                center_H_V.set_align('vcenter')\n",
    "                center_V = workbook.add_format()\n",
    "                center_V.set_align('vcenter')\n",
    "                cell_wrap = workbook.add_format()\n",
    "                cell_wrap.set_text_wrap()\n",
    "\n",
    "                # Настройка ширины колонок\n",
    "                worksheet.set_column(0, 0, 35)  # A  https://xlsxwriter.readthedocs.io/worksheet.html#set_column\n",
    "                worksheet.set_column(1, 1, 20) # B\n",
    "                worksheet.set_column(2, 2, 40) # C\n",
    "                worksheet.set_column(3, 3, 135) # D\n",
    "                worksheet.set_column(4, 4, 45) # E\n",
    "\n",
    "                worksheet.write('A1', 'Наименование', bold)\n",
    "                worksheet.write('B1', 'Зарплата', bold)\n",
    "                worksheet.write('C1', 'Компания', bold)\n",
    "                worksheet.write('D1', 'Описание', bold)\n",
    "                worksheet.write('E1', 'Ссылка', bold)\n",
    "\n",
    "                row = 1\n",
    "                col = 0\n",
    "                for i in jobs:\n",
    "                        worksheet.write_string (row, col, i[0], center_V)\n",
    "                        worksheet.write_string (row, col + 1, i[1], center_H_V)\n",
    "                        worksheet.write_string (row, col + 2, i[2], center_H_V)\n",
    "                        worksheet.write_string (row, col + 3, i[3], cell_wrap)\n",
    "                        # worksheet.write_url (row, col + 4, i[4], center_H_V) \n",
    "                        worksheet.write_url (row, col + 4, i[4])\n",
    "                        row += 1\n",
    "\n",
    "                print('OK')\n",
    "        workbook.close()\n",
    "\n",
    "hh_parse(base_url, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Var.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Парсим на Python\n",
    "\n",
    "HH позволяет найти работу в России. Данный рекрутинговый ресурс обладает самой большой базой данных вакансий. HH делится удобным api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#код в ссылке https://gist.github.com/fuwiak/9c695b51c33b2e052c5a721383705a9c\n",
    "#код с ссылки запускаем так(BASH) python3 hh_parser.py\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "number_of_pages = 100\n",
    "#number_of_ads = number_of_pages * per_page\n",
    "\n",
    "job_title = [\"'Data Analyst' and 'data scientist'\"]\n",
    "for job in job_title:\n",
    "    data=[]\n",
    "    for i in range(number_of_pages):\n",
    "        url = 'https://api.hh.ru/vacancies'\n",
    "        par = {'text': job, 'area':'113','per_page':'10', 'page':i}\n",
    "        r = requests.get(url, params=par)\n",
    "        e=r.json()\n",
    "        data.append(e)\n",
    "        vacancy_details = data[0]['items'][0].keys()\n",
    "        df = pd.DataFrame(columns= list(vacancy_details))\n",
    "        ind = 0\n",
    "        for i in range(len(data)):\n",
    "            for j in range(len(data[i]['items'])):\n",
    "                df.loc[ind] = data[i]['items'][j]\n",
    "                ind+=1\n",
    "    csv_name = job+\".csv\"\n",
    "    df.to_csv(csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге мы получили файл csv с названием указанным в job_title.\n",
    "В указанном будет загружен один файл с вакансиями с фразой\n",
    "«Data Analyst» и «data scientist». Если хотите отдельно поменяйте строку на"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=['Data Analyst', 'Data Scientist', 'data science', 'data analysis', 'data engineer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда вы получаете 2 файла с этими названиями.\n",
    "\n",
    "\n",
    "Что интересно, есть и другие операторы кроме «and». С их помощью можно искать точные совпадения. [Подробнее](https://hh.ru/article/309400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **What time is it? Its Pandas Time!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собранные таким образом объявления будут разделены на группы в соответствии с информацией содержащейся в них или описанием их метаданных. Например: город; позиция; вилка зарплаты; категория вакансии. В этом случае одно объявление может принадлежать нескольким категориям.\n",
    "Сейчас займемся данными, которые связанны с позицией \"data scientist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data/\"data scientist.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что сделать, чтобы поменять название колонки “Unnamed”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed:0':'index'}, inplace=True)\n",
    "df.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Самый главный вопрос — ЗП*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast # run code from string for example ast.literal_eval(\"1+1\") \n",
    "\n",
    "salaries = df.salary.dropna() # remove all NA's from dataframe\n",
    "currencies = [ast.literal_eval(salaries.iloc[i])['currency'] for i in range(len(salaries))]\n",
    "curr = set(currencies) #{'EUR', 'RUR', 'USD'}\n",
    "\n",
    "# divide dataframe salararies by currency\n",
    "rur = [ast.literal_eval(salaries.iloc[i]) for i in range(len(salaries)) if ast.literal_eval(salaries.iloc[i])['currency']=='RUR']\n",
    "eur = [ast.literal_eval(salaries.iloc[i]) for i in range(len(salaries)) if ast.literal_eval(salaries.iloc[i])['currency']=='EUR']\n",
    "usd = [ast.literal_eval(salaries.iloc[i]) for i in range(len(salaries)) if ast.literal_eval(salaries.iloc[i])['currency']=='USD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось разделить зарплаты на валюты, можно попробовать сделать анализ например только для евро. Мы займемся сейчас только рублевыми зарплатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = [x['from'] for x in rur] # lower range of salary\n",
    "fr = list(filter(lambda x: x is not None, fr)) # remove NA's from lower range [0, 100, 200,...]\n",
    "\n",
    "to = [x['to'] for x in rur] # upper range of salary\n",
    "to = list(filter(lambda x: x is not None, to)) # remove NA's from upper range [100, 200, 300,...]\n",
    "\n",
    "import numpy as np\n",
    "salary_range = list(zip(fr, to)) # concatenate upper and lower range  [(0,100), (100, 200), (200, 300)...]\n",
    "av = map(np.mean, salary_range) # convert [(0,100), (100, 200), (200, 300)...] to [50, 150, 250,...]\n",
    "av = round(np.mean(list(av)),1) # average value from [50, 150, 250,...]\n",
    "\n",
    "print(\"average salary as Data Scientist \", av, \"rubles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец-то узнали, около 155 тыс рублей, [Зарплата Data Scientist](https://zarplan.com/zarplata/DATA%20SCIENTIST/РОССИЯ/?q=data%20scientist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для средней зарплаты были такие условия:\n",
    "\n",
    "\n",
    "* не считались вакансии, в которых нет указанной зарплаты (df.salary.dropna)\n",
    "* брались только зарплаты в рублях\n",
    "* если была вилка, тогда бралось среднее значение (например, вилка от 10000 rub до 20000 rub → 15000 rub)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Бонус**\n",
    "\n",
    "*Как востребованы в области \"Data Science\" джуны?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Scince](img/Data_Science.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vacancy_names = df.name # change here to change source of data/words etc\n",
    "cloud = Counter(vacancy_names)\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "cloud = ''\n",
    "for x in list(vacancy_names):\n",
    "    cloud+=x+' '\n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "\n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 8,background_color='white'\n",
    "                     ).generate(cloud)\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "plt.figure(figsize = (16, 16)) \n",
    "plt.imshow(wordcloud)\n",
    "plt.savefig('vacancy_cloud.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Полезность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6 способов оптимизировать рабочий процесс в Pandas** [Оптимизация](https://telegra.ph/6-sposobov-optimizirovat-rabochij-process-v-Pandas-08-03)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
